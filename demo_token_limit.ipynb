{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    回答する際には、前回の会話の内容や文脈を考慮し、自然な会話を継続します。\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "    ※注意※\n",
      "\n",
      "\n",
      "    会話が長時間にわたる場合、会話の流れや文脈を維持することが難しくなる可能性があります。会話の内容や文脈を適切に管理し、会話を自然かつ意味的に継続する努力をしてください。\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "Alice: \n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "Alice: \n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Alice: \n",
      "\n",
      "\n",
      "\n",
      "Bob:\n",
      "\n",
      "\n",
      "    ※"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import END, StateGraph, MessagesState\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# LLMモデルの設定\n",
    "local_path = \"gguf_models/Llama-3-ELYZA-JP-8B-q4_k_m.gguf\"\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=local_path,\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# エージェントの状態を管理するクラス\n",
    "class AgentState(MessagesState):\n",
    "    agent_name: str\n",
    "    other_agent_name: str\n",
    "\n",
    "def create_agent_state(name: str, other_name: str) -> AgentState:\n",
    "    return AgentState(messages=[], agent_name=name, other_agent_name=other_name)\n",
    "\n",
    "# トークン数を制限しつつ会話履歴を管理する関数\n",
    "def get_truncated_conversation_history(messages: List, agent_name: str, other_agent_name: str, max_tokens: int = 400):\n",
    "    text_splitter = TokenTextSplitter(chunk_size=max_tokens, chunk_overlap=0)\n",
    "    \n",
    "    conversation_history = \"\"\n",
    "    for message in reversed(messages):\n",
    "        if isinstance(message, HumanMessage):\n",
    "            conversation_history = f\"{other_agent_name}: {message.content}\\n\" + conversation_history\n",
    "        elif isinstance(message, AIMessage):\n",
    "            conversation_history = f\"{agent_name}: {message.content}\\n\" + conversation_history\n",
    "    \n",
    "    truncated_history = text_splitter.split_text(conversation_history)[-1]\n",
    "    return truncated_history\n",
    "\n",
    "# エージェントの応答を生成する関数\n",
    "\n",
    "# def generate_response(state: AgentState):\n",
    "#     truncated_history = get_truncated_conversation_history(\n",
    "#         state['messages'], \n",
    "#         state['agent_name'], \n",
    "#         state['other_agent_name']\n",
    "#     )\n",
    "    \n",
    "#     prompt = f\"あなたは{state['agent_name']}です。{state['other_agent_name']}と会話をしています。以下の会話を続けてください：\\n\\n{truncated_history}\"\n",
    "    \n",
    "#     response = llm.invoke(prompt)\n",
    "#     return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "def generate_response(state: AgentState):\n",
    "    truncated_history = get_truncated_conversation_history(\n",
    "        state['messages'], \n",
    "        state['agent_name'], \n",
    "        state['other_agent_name']\n",
    "    )\n",
    "    \n",
    "    prompt = f\"\"\"あなたは{state['agent_name']}です。{state['other_agent_name']}と会話をしています。\n",
    "    以下のルールに従って会話を続けてください：\n",
    "    1. 一貫性のある会話を維持してください。\n",
    "    2. 突然話題を変えないでください。\n",
    "    3. 前の会話の文脈を考慮して返答してください。\n",
    "    4. 簡潔に、自然な会話をしてください。\n",
    "\n",
    "    これまでの会話：\n",
    "    {truncated_history}\n",
    "\n",
    "    次の返答を生成してください：\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "# 会話を管理するグラフを作成する関数\n",
    "def create_conversation_graph(agent1_name: str, agent2_name: str):\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    workflow.add_node(\"agent1\", lambda x: generate_response(x))\n",
    "    workflow.add_node(\"agent2\", lambda x: generate_response(x))\n",
    "    \n",
    "    workflow.set_entry_point(\"agent1\")\n",
    "    \n",
    "    workflow.add_edge(\"agent1\", \"agent2\")\n",
    "    workflow.add_edge(\"agent2\", \"agent1\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# 会話グラフの作成\n",
    "conversation = create_conversation_graph(\"Alice\", \"Bob\")\n",
    "\n",
    "# 会話を実行する関数\n",
    "# def run_conversation(turns: int):\n",
    "#     alice_state = create_agent_state(\"Alice\", \"Bob\")\n",
    "#     bob_state = create_agent_state(\"Bob\", \"Alice\")\n",
    "    \n",
    "#     alice_state['messages'].append(HumanMessage(content=\"こんにちは、Bob。今日はいい天気ですね。散歩でもしませんか？\"))\n",
    "    \n",
    "#     for _ in range(turns):\n",
    "#         alice_result = conversation.invoke(alice_state)\n",
    "#         alice_state['messages'].extend(alice_result['messages'])\n",
    "#         bob_state['messages'].extend(alice_result['messages'])\n",
    "        \n",
    "#         bob_result = conversation.invoke(bob_state)\n",
    "#         bob_state['messages'].extend(bob_result['messages'])\n",
    "#         alice_state['messages'].extend(bob_result['messages'])\n",
    "        \n",
    "#         print(f\"Alice: {alice_result['messages'][-1].content}\")\n",
    "#         print(f\"Bob: {bob_result['messages'][-1].content}\")\n",
    "#         print()\n",
    "\n",
    "def run_conversation(turns: int):\n",
    "    alice_state = create_agent_state(\"Alice\", \"Bob\")\n",
    "    bob_state = create_agent_state(\"Bob\", \"Alice\")\n",
    "    \n",
    "    alice_state['messages'].append(HumanMessage(content=\"こんにちは、Bob。今日はいい天気ですね。散歩でもしませんか？\"))\n",
    "    \n",
    "    for _ in range(turns):\n",
    "        alice_result = conversation.invoke(alice_state)\n",
    "        alice_state['messages'].extend(alice_result['messages'])\n",
    "        bob_state['messages'].extend(alice_result['messages'])\n",
    "        \n",
    "        bob_result = conversation.invoke(bob_state)\n",
    "        bob_state['messages'].extend(bob_result['messages'])\n",
    "        alice_state['messages'].extend(bob_result['messages'])\n",
    "        \n",
    "        print(f\"Alice: {alice_result['messages'][-1].content}\")\n",
    "        print(f\"Bob: {bob_result['messages'][-1].content}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "# 会話の実行\n",
    "run_conversation(5)  # 5ターンの会話を実行"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
